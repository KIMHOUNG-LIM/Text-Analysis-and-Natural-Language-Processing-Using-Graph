{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building a Document Topic Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next we will focus on using information and connection between entities taken from bipartite entity-document graph to **train multi-label classifiers** `to predict the document topics`. To do this we will analyze two different approaches.  \n",
    "- `A shallow machine-learning approach` : embeded all the node from bipartite after preprocessing using graph then use the embdeded to train traditional classifiers such as **Random Forest classifier**  \n",
    "- `A more integrated and differentiable approach` : based on graphical neural network on to heterogeneous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "corpus = pd.DataFrame([\n",
    "    {\"id\": _id,\n",
    "     \"text\": reuters.raw(_id).replace(\"\\n\", \"\"), \n",
    "     \"label\": reuters.categories(_id)}\n",
    "    for _id in reuters.fileids()\n",
    " ])\n",
    "# corpus = corpus.loc[:4]\n",
    "\n",
    "# Clean the Text\n",
    "def clean_text(text):\n",
    "    # Remove escape characters\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove quotes around company names\n",
    "    text = re.sub(r'<(.*?)>', r'\\1', text)\n",
    "    return text\n",
    "corpus['clean_text']=corpus[\"text\"].apply(clean_text)\n",
    "# corpus[\"clean_text\"] = corpus[\"text\"].apply(\n",
    "#     lambda x: x.replace(\"\\n\", \"\")\n",
    "#  )\n",
    "\n",
    "#Detect Language within Each Article of dataset\n",
    "def getLanguage(text: str):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return np.nan\n",
    "corpus[\"language\"] = corpus[\"text\"].apply(detect)\n",
    "\n",
    "# load the model NLP and apply to the clean text\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "corpus[\"parsed\"] = corpus[\"clean_text\"]\\\n",
    ".apply(nlp)\n",
    "\n",
    "#Extracting Keyword fro corpus\n",
    "from gensim.summarization import keywords\n",
    "corpus['keywords'] = corpus[\"clean_text\"].apply(lambda text: keywords(text, split=True, scores=True, pos_filter=('NN', 'JJ'), lemmatize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEntities(ents, minValue=1, typeFilters=[\"GPE\", \"ORG\", \"PERSON\"]):\n",
    "    entities = pd.DataFrame([\n",
    "        {\n",
    "            \"lemma\": e.lemma_,\n",
    "            \"lower\": e.lemma_.lower(),\n",
    "            \"type\": e.label_\n",
    "        } for e in ents if hasattr(e, \"label_\")\n",
    "    ])\n",
    "    if len(entities) == 0:\n",
    "        return pd.DataFrame()\n",
    "    g = entities.groupby([\"type\", \"lower\"])\n",
    "    summary = pd.concat({\n",
    "        \"alias\": g.apply(lambda x: x[\"lemma\"].unique()),\n",
    "        \"count\": g[\"lower\"].count()\n",
    "    }, axis=1)\n",
    "    \n",
    "    # Use boolean indexing to filter rows based on typeFilters\n",
    "    filtered_summary = summary[summary[\"count\"] > minValue]\n",
    "    filtered_summary = filtered_summary[filtered_summary.index.get_level_values('type').isin(typeFilters)]\n",
    "    \n",
    "    return filtered_summary\n",
    "\n",
    "def getOrEmpty(parsed, _type):\n",
    "    try:\n",
    "        return list(parsed.loc[_type][\"count\"]\\\n",
    "            .sort_values(ascending=False).to_dict().items())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def toField(ents):\n",
    "    typeFilters = [\"GPE\", \"ORG\", \"PERSON\"]\n",
    "    parsed = extractEntities(ents, 1, typeFilters)\n",
    "    return pd.Series({_type: getOrEmpty(parsed, _type)\n",
    "                      for _type in typeFilters})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When training topic classifier, we must restrict our focus to only those document that belong to such labels. So, First we will consider the **top 10 common topic across the document**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earn', 3964),\n",
       " ('acq', 2369),\n",
       " ('money-fx', 717),\n",
       " ('grain', 582),\n",
       " ('crude', 578),\n",
       " ('trade', 485),\n",
       " ('interest', 478),\n",
       " ('ship', 286),\n",
       " ('wheat', 283),\n",
       " ('corn', 237)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "topics = Counter(\n",
    " [label \n",
    " for document_labels in corpus[\"label\"] \n",
    " for label in document_labels]\n",
    ").most_common(10)\n",
    "\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicsList = [topic[0] for topic in topics]\n",
    "topicsSet = set(topicsList)\n",
    "dataset = corpus[corpus[\"label\"].apply(\n",
    " lambda x: len(topicsSet.intersection(x))>0\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>language</th>\n",
       "      <th>parsed</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>asian exporters fear damage from u.s.-japan ri...</td>\n",
       "      <td>en</td>\n",
       "      <td>(asian, exporters, fear, damage, from, u.s.-ja...</td>\n",
       "      <td>[(trading, 0.4615130639538527), (said, 0.31598...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>china daily says vermin eat 7-12 pct grain sto...</td>\n",
       "      <td>en</td>\n",
       "      <td>(china, daily, says, vermin, eat, 7, -, 12, pc...</td>\n",
       "      <td>[(vermin, 0.312061438028717), (daily, 0.261102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>japan to revise long-term energy demand downwa...</td>\n",
       "      <td>en</td>\n",
       "      <td>(japan, to, revise, long, -, term, energy, dem...</td>\n",
       "      <td>[(energy demand, 0.36686090947000344), (nuclea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/14832</td>\n",
       "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER  Th...</td>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>thai trade deficit widens in first quarter  th...</td>\n",
       "      <td>en</td>\n",
       "      <td>(thai, trade, deficit, widens, in, first, quar...</td>\n",
       "      <td>[(pct, 0.5457455609144308), (export, 0.2656069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test/14839</td>\n",
       "      <td>AUSTRALIAN FOREIGN SHIP BAN ENDS BUT NSW PORTS...</td>\n",
       "      <td>[ship]</td>\n",
       "      <td>australian foreign ship ban ends but nsw ports...</td>\n",
       "      <td>en</td>\n",
       "      <td>(australian, foreign, ship, ban, ends, but, ns...</td>\n",
       "      <td>[(dispute shipping, 0.28151707573325435), (nsw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>training/999</td>\n",
       "      <td>U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...</td>\n",
       "      <td>[interest, money-fx]</td>\n",
       "      <td>u.k. money market shortage forecast revised do...</td>\n",
       "      <td>en</td>\n",
       "      <td>(u.k, ., money, market, shortage, forecast, re...</td>\n",
       "      <td>[(forecast, 0.3364640504513776), (market, 0.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>training/9992</td>\n",
       "      <td>KNIGHT-RIDDER INC &amp;lt;KRN&gt; SETS QUARTERLY  Qtl...</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>knight-ridder inc &amp;lt;krn&gt; sets quarterly  qtl...</td>\n",
       "      <td>en</td>\n",
       "      <td>(knight, -, ridder, inc, &amp;, lt;krn, &gt;, sets, q...</td>\n",
       "      <td>[(sets, 0.33086349685229766), (april, 0.330863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>training/9993</td>\n",
       "      <td>TECHNITROL INC &amp;lt;TNL&gt; SETS QUARTERLY  Qtly d...</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>technitrol inc &amp;lt;tnl&gt; sets quarterly  qtly d...</td>\n",
       "      <td>en</td>\n",
       "      <td>(technitrol, inc, &amp;, lt;tnl, &gt;, sets, quarterl...</td>\n",
       "      <td>[(april, 0.47842480045583535), (sets, 0.336643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>training/9994</td>\n",
       "      <td>NATIONWIDE CELLULAR SERVICE INC &amp;lt;NCEL&gt; 4TH ...</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>nationwide cellular service inc &amp;lt;ncel&gt; 4th ...</td>\n",
       "      <td>en</td>\n",
       "      <td>(nationwide, cellular, service, inc, &amp;, lt;nce...</td>\n",
       "      <td>[(shrs, 0.48295618305741017), (loss, 0.4437435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>training/9995</td>\n",
       "      <td>&amp;lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP&gt; YEAR ...</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>&amp;lt;a.h.a. automotive technologies corp&gt; year ...</td>\n",
       "      <td>en</td>\n",
       "      <td>(&amp;, lt;a.h.a, ., automotive, technologies, cor...</td>\n",
       "      <td>[(net, 0.3541015281187543), (cts, 0.3445463645...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9034 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "0         test/14826  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...   \n",
       "1         test/14828  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...   \n",
       "2         test/14829  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...   \n",
       "3         test/14832  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER  Th...   \n",
       "5         test/14839  AUSTRALIAN FOREIGN SHIP BAN ENDS BUT NSW PORTS...   \n",
       "...              ...                                                ...   \n",
       "10783   training/999  U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...   \n",
       "10784  training/9992  KNIGHT-RIDDER INC &lt;KRN> SETS QUARTERLY  Qtl...   \n",
       "10785  training/9993  TECHNITROL INC &lt;TNL> SETS QUARTERLY  Qtly d...   \n",
       "10786  training/9994  NATIONWIDE CELLULAR SERVICE INC &lt;NCEL> 4TH ...   \n",
       "10787  training/9995  &lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP> YEAR ...   \n",
       "\n",
       "                                                label  \\\n",
       "0                                             [trade]   \n",
       "1                                             [grain]   \n",
       "2                                    [crude, nat-gas]   \n",
       "3      [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "5                                              [ship]   \n",
       "...                                               ...   \n",
       "10783                            [interest, money-fx]   \n",
       "10784                                          [earn]   \n",
       "10785                                          [earn]   \n",
       "10786                                          [earn]   \n",
       "10787                                          [earn]   \n",
       "\n",
       "                                              clean_text language  \\\n",
       "0      asian exporters fear damage from u.s.-japan ri...       en   \n",
       "1      china daily says vermin eat 7-12 pct grain sto...       en   \n",
       "2      japan to revise long-term energy demand downwa...       en   \n",
       "3      thai trade deficit widens in first quarter  th...       en   \n",
       "5      australian foreign ship ban ends but nsw ports...       en   \n",
       "...                                                  ...      ...   \n",
       "10783  u.k. money market shortage forecast revised do...       en   \n",
       "10784  knight-ridder inc &lt;krn> sets quarterly  qtl...       en   \n",
       "10785  technitrol inc &lt;tnl> sets quarterly  qtly d...       en   \n",
       "10786  nationwide cellular service inc &lt;ncel> 4th ...       en   \n",
       "10787  &lt;a.h.a. automotive technologies corp> year ...       en   \n",
       "\n",
       "                                                  parsed  \\\n",
       "0      (asian, exporters, fear, damage, from, u.s.-ja...   \n",
       "1      (china, daily, says, vermin, eat, 7, -, 12, pc...   \n",
       "2      (japan, to, revise, long, -, term, energy, dem...   \n",
       "3      (thai, trade, deficit, widens, in, first, quar...   \n",
       "5      (australian, foreign, ship, ban, ends, but, ns...   \n",
       "...                                                  ...   \n",
       "10783  (u.k, ., money, market, shortage, forecast, re...   \n",
       "10784  (knight, -, ridder, inc, &, lt;krn, >, sets, q...   \n",
       "10785  (technitrol, inc, &, lt;tnl, >, sets, quarterl...   \n",
       "10786  (nationwide, cellular, service, inc, &, lt;nce...   \n",
       "10787  (&, lt;a.h.a, ., automotive, technologies, cor...   \n",
       "\n",
       "                                                keywords  \n",
       "0      [(trading, 0.4615130639538527), (said, 0.31598...  \n",
       "1      [(vermin, 0.312061438028717), (daily, 0.261102...  \n",
       "2      [(energy demand, 0.36686090947000344), (nuclea...  \n",
       "3      [(pct, 0.5457455609144308), (export, 0.2656069...  \n",
       "5      [(dispute shipping, 0.28151707573325435), (nsw...  \n",
       "...                                                  ...  \n",
       "10783  [(forecast, 0.3364640504513776), (market, 0.33...  \n",
       "10784  [(sets, 0.33086349685229766), (april, 0.330863...  \n",
       "10785  [(april, 0.47842480045583535), (sets, 0.336643...  \n",
       "10786  [(shrs, 0.48295618305741017), (loss, 0.4437435...  \n",
       "10787  [(net, 0.3541015281187543), (cts, 0.3445463645...  \n",
       "\n",
       "[9034 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have extracted structured dataset, we are ready to start training our topic models and evaluating their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Shallow Learning Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we will prepare the dataset onto the bipartite graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Some KeyWords**:  \n",
    "- `Embedding`: is vector representation of items here it can represent node or entities and their relationship within the graph   \n",
    "- `Grid Search Cross Validation` : technique use to fine tune hyperparameter( settings that are not learned from the data but need to be specified beforehand) of a ML model. It searches through *a predefined set of hyperparameter*, evaluate each combination using cross-validation and identifies the combination that yields the best performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entities = dataset[\"parsed\"].apply(lambda x: toField(x.ents))\n",
    "merged = pd.concat([dataset, entities], axis=1)\n",
    "\n",
    "\n",
    "edges = pd.DataFrame([\n",
    "{\"source\": _id, \"target\": keyword, \"weight\": score, \"type\":\n",
    "_type}\n",
    "for _id, row in merged.iterrows()\n",
    "for _type in [\"keywords\", \"GPE\", \"ORG\", \"PERSON\"]\n",
    "for (keyword, score) in row[_type]\n",
    "])\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "# Assuming 'edges' is a DataFrame with columns 'source' and 'target'\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes with bipartite attribute\n",
    "G.add_nodes_from(edges[\"source\"].unique(), bipartite=0) #1st set -- Document\n",
    "G.add_nodes_from(edges[\"target\"].unique(), bipartite=1) #2nd set -- Keywords of Texts\n",
    "\n",
    "# Add edges\n",
    "G.add_edges_from([(row[\"source\"], row[\"target\"]) for _, row in edges.iterrows()])\n",
    "\n",
    "\n",
    "# take the two set from graph and define as doc-node and entity-node\n",
    "document_nodes = {n\n",
    "        for n, d in G.nodes(data=True)\n",
    "        if d[\"bipartite\"] == 0}\n",
    "entity_nodes = {n\n",
    "        for n, d in G.nodes(data=True)\n",
    "        if d[\"bipartite\"] == 1}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we load the model node2vec on to the graph which we will embeded all the node within the graph into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\envs\\NLP1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Computing transition probabilities:   0%|          | 0/19836 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 19836/19836 [00:46<00:00, 426.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "from node2vec import Node2Vec\n",
    "\n",
    "node2vec = Node2Vec(G, dimensions=10, workers=6)  # Use the number of available CPU cores\n",
    "model = node2vec.fit(window=20)\n",
    "embeddings = model.wv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0529803 , -0.28791276, -0.01597374, ..., -0.3570909 ,\n",
       "        -0.29400387, -0.02616971],\n",
       "       [ 0.5733612 , -0.47963986,  0.23776445, ..., -0.02688649,\n",
       "        -0.12002277,  0.2997235 ],\n",
       "       [ 0.67850226, -0.78957736,  0.09599695, ...,  0.09617652,\n",
       "        -0.42856067,  0.0775395 ],\n",
       "       ...,\n",
       "       [-0.94714403,  0.05905417, -0.81775063, ...,  0.19457108,\n",
       "        -0.23917626,  0.00524572],\n",
       "       [-0.5830384 , -0.84181184, -0.4153224 , ..., -1.0292932 ,\n",
       "        -1.0040509 ,  0.44983572],\n",
       "       [ 0.63257056, -0.4008611 , -0.03733917, ..., -1.3890903 ,\n",
       "        -1.7813815 , -0.9665787 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NExt for enhancing the efficiency of graph-based ML, we will precomputing embedding, save them to disk in **pickle format** with filename based on the dimensions and window parameter and use them in optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension=10\n",
    "# window=20\n",
    "# pd.DataFrame(embeddings.vectors, index=embeddings.index2word)\\\n",
    "#     .to_pickle(f\"./embeddings/bipartiteGraphEmbeddings_{dimensions}_{window}.p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>-0.068634</td>\n",
       "      <td>-0.108728</td>\n",
       "      <td>0.279320</td>\n",
       "      <td>0.502636</td>\n",
       "      <td>-0.352387</td>\n",
       "      <td>-0.141525</td>\n",
       "      <td>0.122002</td>\n",
       "      <td>-0.174865</td>\n",
       "      <td>0.270644</td>\n",
       "      <td>-0.536599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mln</th>\n",
       "      <td>0.806816</td>\n",
       "      <td>-0.031284</td>\n",
       "      <td>0.831844</td>\n",
       "      <td>0.338622</td>\n",
       "      <td>-0.450020</td>\n",
       "      <td>-0.301777</td>\n",
       "      <td>0.314351</td>\n",
       "      <td>-0.175108</td>\n",
       "      <td>0.585830</td>\n",
       "      <td>-0.098098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net</th>\n",
       "      <td>0.927049</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>1.356840</td>\n",
       "      <td>0.432589</td>\n",
       "      <td>-0.294489</td>\n",
       "      <td>-0.322550</td>\n",
       "      <td>0.490149</td>\n",
       "      <td>-0.077926</td>\n",
       "      <td>0.527095</td>\n",
       "      <td>0.199232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u.s.</th>\n",
       "      <td>-0.144313</td>\n",
       "      <td>0.180694</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.834751</td>\n",
       "      <td>-0.384607</td>\n",
       "      <td>-0.121756</td>\n",
       "      <td>-0.214999</td>\n",
       "      <td>0.088578</td>\n",
       "      <td>0.340159</td>\n",
       "      <td>-0.201328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dlrs</th>\n",
       "      <td>0.167431</td>\n",
       "      <td>-0.229972</td>\n",
       "      <td>0.686198</td>\n",
       "      <td>0.227649</td>\n",
       "      <td>-0.532566</td>\n",
       "      <td>-0.382044</td>\n",
       "      <td>0.405773</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.351097</td>\n",
       "      <td>-0.298843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liedtke</th>\n",
       "      <td>0.161181</td>\n",
       "      <td>-0.653445</td>\n",
       "      <td>0.384399</td>\n",
       "      <td>0.404352</td>\n",
       "      <td>-0.495372</td>\n",
       "      <td>-0.831178</td>\n",
       "      <td>1.201550</td>\n",
       "      <td>-0.669810</td>\n",
       "      <td>-0.097228</td>\n",
       "      <td>-0.398567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minerals properties</th>\n",
       "      <td>-0.126188</td>\n",
       "      <td>-0.666247</td>\n",
       "      <td>1.043137</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>-1.271500</td>\n",
       "      <td>0.104546</td>\n",
       "      <td>-0.107410</td>\n",
       "      <td>-1.483430</td>\n",
       "      <td>1.339801</td>\n",
       "      <td>0.451293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sand technology</th>\n",
       "      <td>0.562546</td>\n",
       "      <td>-0.375001</td>\n",
       "      <td>0.410943</td>\n",
       "      <td>0.634887</td>\n",
       "      <td>-0.779979</td>\n",
       "      <td>-0.991260</td>\n",
       "      <td>0.834942</td>\n",
       "      <td>-0.043466</td>\n",
       "      <td>0.543723</td>\n",
       "      <td>0.262858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schlecht</th>\n",
       "      <td>-0.109026</td>\n",
       "      <td>0.547412</td>\n",
       "      <td>1.187024</td>\n",
       "      <td>0.542943</td>\n",
       "      <td>0.514080</td>\n",
       "      <td>-0.357270</td>\n",
       "      <td>-0.807087</td>\n",
       "      <td>-0.077646</td>\n",
       "      <td>0.053627</td>\n",
       "      <td>-0.773175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int</th>\n",
       "      <td>0.100956</td>\n",
       "      <td>0.455052</td>\n",
       "      <td>0.339058</td>\n",
       "      <td>0.432554</td>\n",
       "      <td>-0.911695</td>\n",
       "      <td>-0.426637</td>\n",
       "      <td>-0.133107</td>\n",
       "      <td>-1.046802</td>\n",
       "      <td>-0.098659</td>\n",
       "      <td>-0.313944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19836 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         1         2         3         4  \\\n",
       "said                -0.068634 -0.108728  0.279320  0.502636 -0.352387   \n",
       "mln                  0.806816 -0.031284  0.831844  0.338622 -0.450020   \n",
       "net                  0.927049  0.026581  1.356840  0.432589 -0.294489   \n",
       "u.s.                -0.144313  0.180694  0.365246  0.834751 -0.384607   \n",
       "dlrs                 0.167431 -0.229972  0.686198  0.227649 -0.532566   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "liedtke              0.161181 -0.653445  0.384399  0.404352 -0.495372   \n",
       "minerals properties -0.126188 -0.666247  1.043137 -0.001206 -1.271500   \n",
       "sand technology      0.562546 -0.375001  0.410943  0.634887 -0.779979   \n",
       "schlecht            -0.109026  0.547412  1.187024  0.542943  0.514080   \n",
       "int                  0.100956  0.455052  0.339058  0.432554 -0.911695   \n",
       "\n",
       "                            5         6         7         8         9  \n",
       "said                -0.141525  0.122002 -0.174865  0.270644 -0.536599  \n",
       "mln                 -0.301777  0.314351 -0.175108  0.585830 -0.098098  \n",
       "net                 -0.322550  0.490149 -0.077926  0.527095  0.199232  \n",
       "u.s.                -0.121756 -0.214999  0.088578  0.340159 -0.201328  \n",
       "dlrs                -0.382044  0.405773  0.072278  0.351097 -0.298843  \n",
       "...                       ...       ...       ...       ...       ...  \n",
       "liedtke             -0.831178  1.201550 -0.669810 -0.097228 -0.398567  \n",
       "minerals properties  0.104546 -0.107410 -1.483430  1.339801  0.451293  \n",
       "sand technology     -0.991260  0.834942 -0.043466  0.543723  0.262858  \n",
       "schlecht            -0.357270 -0.807087 -0.077646  0.053627 -0.773175  \n",
       "int                 -0.426637 -0.133107 -1.046802 -0.098659 -0.313944  \n",
       "\n",
       "[19836 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus1= pd.read_pickle('graphEmbeddings_10_20.p')\n",
    "corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Bipartite Graph=====\n",
      "Number of nodes: 19836\n",
      "Number of edges: 54064\n",
      "Average degree: 5.45109901189756\n"
     ]
    }
   ],
   "source": [
    "print(\"=====Bipartite Graph=====\")\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "print(\"Average degree:\", sum(dict(G.degree()).values()) / G.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> and we gonna make a class to use in grid search cross-validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn, acq, money-fx, grain, crude, trade, interest, ship, wheat, corn, "
     ]
    }
   ],
   "source": [
    "for i in topicsList: print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmbeddingsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, embeddings_file):\n",
    "        self.embeddings_file = embeddings_file  # Add this line to store the embeddings file path\n",
    "        self.embeddings = pd.read_pickle(embeddings_file)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, documents):\n",
    "        return np.array([self.get_document_vector(document) for document in documents])\n",
    "\n",
    "    def get_word_vector(self, word):\n",
    "        if word in self.embeddings.index:\n",
    "            return self.embeddings.loc[word].values\n",
    "        else:\n",
    "            return np.zeros_like(self.embeddings.values[0])\n",
    "\n",
    "    def get_document_vector(self, document):\n",
    "        word_vectors = [self.get_word_vector(f'{word}') for word in document]\n",
    "        document_vector = np.mean(word_vectors, axis=0)\n",
    "        return document_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To build a modeling training pipeline, we will split our corpus into training and test sets, where the dataset already tell us which article to be a test set and which one to be training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the dataset into training and test sets\n",
    "def train_test_split(corpus):\n",
    "    train_mask = corpus['id'].str.contains(\"training/\")\n",
    "    test_mask = corpus['id'].str.contains(\"test/\")\n",
    "\n",
    "    train = corpus[train_mask]\n",
    "    test = corpus[test_mask]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>language</th>\n",
       "      <th>parsed</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>training/10</td>\n",
       "      <td>COMPUTER TERMINAL SYSTEMS &amp;lt;CPML&gt; COMPLETES ...</td>\n",
       "      <td>[acq]</td>\n",
       "      <td>computer terminal systems &amp;lt;cpml&gt; completes ...</td>\n",
       "      <td>en</td>\n",
       "      <td>(computer, terminal, systems, &amp;, lt;cpml, &gt;, c...</td>\n",
       "      <td>[(price, 0.2331391311935398), (said, 0.2093850...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>training/1000</td>\n",
       "      <td>NATIONAL AMUSEMENTS AGAIN UPS VIACOM &amp;lt;VIA&gt; ...</td>\n",
       "      <td>[acq]</td>\n",
       "      <td>national amusements again ups viacom &amp;lt;via&gt; ...</td>\n",
       "      <td>en</td>\n",
       "      <td>(national, amusements, again, ups, viacom, &amp;, ...</td>\n",
       "      <td>[(viacom, 0.46000329134063395), (holdings, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>training/10000</td>\n",
       "      <td>ROGERS &amp;lt;ROG&gt; SEES 1ST QTR NET UP SIGNIFICAN...</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>rogers &amp;lt;rog&gt; sees 1st qtr net up significan...</td>\n",
       "      <td>en</td>\n",
       "      <td>(rogers, &amp;, lt;rog, &gt;, sees, 1st, qtr, net, up...</td>\n",
       "      <td>[(quarter, 0.3204543230825579), (rogers, 0.296...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "3020     training/10  COMPUTER TERMINAL SYSTEMS &lt;CPML> COMPLETES ...   \n",
       "3022   training/1000  NATIONAL AMUSEMENTS AGAIN UPS VIACOM &lt;VIA> ...   \n",
       "3023  training/10000  ROGERS &lt;ROG> SEES 1ST QTR NET UP SIGNIFICAN...   \n",
       "\n",
       "       label                                         clean_text language  \\\n",
       "3020   [acq]  computer terminal systems &lt;cpml> completes ...       en   \n",
       "3022   [acq]  national amusements again ups viacom &lt;via> ...       en   \n",
       "3023  [earn]  rogers &lt;rog> sees 1st qtr net up significan...       en   \n",
       "\n",
       "                                                 parsed  \\\n",
       "3020  (computer, terminal, systems, &, lt;cpml, >, c...   \n",
       "3022  (national, amusements, again, ups, viacom, &, ...   \n",
       "3023  (rogers, &, lt;rog, >, sees, 1st, qtr, net, up...   \n",
       "\n",
       "                                               keywords  \n",
       "3020  [(price, 0.2331391311935398), (said, 0.2093850...  \n",
       "3022  [(viacom, 0.46000329134063395), (holdings, 0.2...  \n",
       "3023  [(quarter, 0.3204543230825579), (rogers, 0.296...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "(6489, 7) (2545, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check data types and shapes\n",
    "print(type(train), type(test))\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> after we extract the train and test set from the dataset, now we will `get feature` (clean text that already clean and apply NLP model on >> corpus['parsed']) and `get label` to get label topic of each article, where each label within each article will transform into 0, or 1 if the label is define within that article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(corpus):\n",
    "    return corpus[\"parsed\"]\n",
    "\n",
    "def get_labels(corpus, topicsList):\n",
    "    return corpus[\"label\"].apply(\n",
    "        lambda labels: pd.Series(\n",
    "            {label: 1 for label in labels}\n",
    "        ).reindex(topicsList).fillna(0)\n",
    "    )[topicsList]\n",
    "\n",
    "def get_features_and_labels(corpus):\n",
    "    return get_features(corpus), get_labels(corpus, topicsList)\n",
    "\n",
    "features, labels = get_features_and_labels(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earn</th>\n",
       "      <th>acq</th>\n",
       "      <th>money-fx</th>\n",
       "      <th>grain</th>\n",
       "      <th>crude</th>\n",
       "      <th>trade</th>\n",
       "      <th>interest</th>\n",
       "      <th>ship</th>\n",
       "      <th>wheat</th>\n",
       "      <th>corn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      earn  acq  money-fx  grain  crude  trade  interest  ship  wheat  corn\n",
       "3020   0.0  1.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3022   0.0  1.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3023   1.0  0.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'>\n",
      "(6489,) (6489, 10)\n"
     ]
    }
   ],
   "source": [
    "# Check data types and shapes\n",
    "print(type(features), type(labels))\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we will put everything in a pipeline so this will allows you to chain multiple steps together, ensuring that the data flows seamlessly from one step to the next\n",
    "- Fist it will embeded the input corpus text into vector with the class that being made for tranforming those corpus name `EmbeddingsTransformer`  \n",
    "- Next it will train the model using the above transforming data for training the model.  \n",
    "- when prediction the model will transform the data first the same as before training the model, so we do not to call it many time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Instantiate the modeling pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"embeddings\", EmbeddingsTransformer(\"graphEmbeddings_10_20.p\")),  # Load the embeddings file\n",
    "    (\"model\", MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Define the parameter space and perform grid search\n",
    "from sklearn.metrics import f1_score \n",
    "from glob import glob\n",
    "param_grid = {\n",
    "    \"embeddings__embeddings_file\": glob(\"graphEmbeddings_*\"),\n",
    "    \"model__estimator__n_estimators\": [50, 100],\n",
    "    \"model__estimator__max_features\": [0.2, 0.3],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, n_jobs=-1, \n",
    "                           scoring=lambda y_true, y_pred: f1_score(y_true, y_pred,average='weighted'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3020     (computer, terminal, systems, &, lt;cpml, >, c...\n",
       "3022     (national, amusements, again, ups, viacom, &, ...\n",
       "3023     (rogers, &, lt;rog, >, sees, 1st, qtr, net, up...\n",
       "3024     (island, telephone, share, split, approved,  ,...\n",
       "3025     (u.k, ., growing, impatient, with, japan, -, t...\n",
       "                               ...                        \n",
       "10783    (u.k, ., money, market, shortage, forecast, re...\n",
       "10784    (knight, -, ridder, inc, &, lt;krn, >, sets, q...\n",
       "10785    (technitrol, inc, &, lt;tnl, >, sets, quarterl...\n",
       "10786    (nationwide, cellular, service, inc, &, lt;nce...\n",
       "10787    (&, lt;a.h.a, ., automotive, technologies, cor...\n",
       "Name: parsed, Length: 6489, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\envs\\NLP1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Train the topic model\n",
    "model = grid_search.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;embeddings&#x27;,\n",
       "                 EmbeddingsTransformer(embeddings_file=&#x27;graphEmbeddings_10_20.p&#x27;)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(max_features=0.2,\n",
       "                                                                        n_estimators=50)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;embeddings&#x27;,\n",
       "                 EmbeddingsTransformer(embeddings_file=&#x27;graphEmbeddings_10_20.p&#x27;)),\n",
       "                (&#x27;model&#x27;,\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(max_features=0.2,\n",
       "                                                                        n_estimators=50)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">EmbeddingsTransformer</label><div class=\"sk-toggleable__content\"><pre>EmbeddingsTransformer(embeddings_file=&#x27;graphEmbeddings_10_20.p&#x27;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(max_features=0.2,\n",
       "                                                       n_estimators=50))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=0.2, n_estimators=50)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=0.2, n_estimators=50)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('embeddings',\n",
       "                 EmbeddingsTransformer(embeddings_file='graphEmbeddings_10_20.p')),\n",
       "                ('model',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(max_features=0.2,\n",
       "                                                                        n_estimators=50)))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next we will **evaluate the performance of the model** that we have train on random forest classifier with the help of **grid search** to find the best parameter for random forest using the test set that we have split from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, features, topicsList):\n",
    "    return pd.DataFrame(\n",
    "        model.predict(features), \n",
    "        columns=topicsList, \n",
    "        index=features.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_predictions(model, get_features(test), topicsList)\n",
    "labels = get_labels(test, topicsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earn</th>\n",
       "      <th>acq</th>\n",
       "      <th>money-fx</th>\n",
       "      <th>grain</th>\n",
       "      <th>crude</th>\n",
       "      <th>trade</th>\n",
       "      <th>interest</th>\n",
       "      <th>ship</th>\n",
       "      <th>wheat</th>\n",
       "      <th>corn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2545 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      earn  acq  money-fx  grain  crude  trade  interest  ship  wheat  corn\n",
       "0      0.0  0.0       0.0    0.0    0.0    1.0       0.0   0.0    0.0   0.0\n",
       "1      0.0  0.0       0.0    1.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "2      0.0  0.0       0.0    0.0    1.0    0.0       0.0   0.0    0.0   0.0\n",
       "3      0.0  0.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "5      0.0  0.0       0.0    0.0    0.0    0.0       0.0   1.0    0.0   0.0\n",
       "...    ...  ...       ...    ...    ...    ...       ...   ...    ...   ...\n",
       "3012   0.0  0.0       0.0    0.0    1.0    0.0       0.0   0.0    0.0   0.0\n",
       "3013   0.0  0.0       0.0    1.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3014   0.0  1.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3015   0.0  0.0       1.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3016   0.0  0.0       0.0    0.0    0.0    0.0       0.0   1.0    0.0   0.0\n",
       "\n",
       "[2545 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earn</th>\n",
       "      <th>acq</th>\n",
       "      <th>money-fx</th>\n",
       "      <th>grain</th>\n",
       "      <th>crude</th>\n",
       "      <th>trade</th>\n",
       "      <th>interest</th>\n",
       "      <th>ship</th>\n",
       "      <th>wheat</th>\n",
       "      <th>corn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2545 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      earn  acq  money-fx  grain  crude  trade  interest  ship  wheat  corn\n",
       "0      0.0  0.0       0.0    0.0    0.0    1.0       0.0   0.0    0.0   0.0\n",
       "1      0.0  0.0       0.0    1.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "2      0.0  0.0       0.0    0.0    1.0    0.0       0.0   0.0    0.0   0.0\n",
       "3      0.0  0.0       0.0    1.0    0.0    1.0       0.0   0.0    0.0   1.0\n",
       "5      0.0  0.0       0.0    0.0    0.0    0.0       0.0   1.0    0.0   0.0\n",
       "...    ...  ...       ...    ...    ...    ...       ...   ...    ...   ...\n",
       "3012   0.0  0.0       0.0    0.0    1.0    0.0       0.0   0.0    0.0   0.0\n",
       "3013   0.0  0.0       0.0    1.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3014   0.0  1.0       0.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3015   0.0  0.0       1.0    0.0    0.0    0.0       0.0   0.0    0.0   0.0\n",
       "3016   0.0  0.0       0.0    0.0    0.0    0.0       0.0   1.0    0.0   0.0\n",
       "\n",
       "[2545 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earn         65.0\n",
       "acq         108.0\n",
       "money-fx     80.0\n",
       "grain        30.0\n",
       "crude        47.0\n",
       "trade        52.0\n",
       "interest     76.0\n",
       "ship         49.0\n",
       "wheat        48.0\n",
       "corn         47.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels - preds).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earn         65\n",
       "acq         108\n",
       "money-fx     80\n",
       "grain        30\n",
       "crude        47\n",
       "trade        52\n",
       "interest     76\n",
       "ship         49\n",
       "wheat        48\n",
       "corn         47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels != preds).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839971295299606"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 1 - (labels - preds).abs().sum().sum() / labels.abs().sum().sum()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is calculated as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = 1 - \\frac{\\sum_{i,j} |\\text{labels}_{ij} - \\text{preds}_{ij}|}{\\sum_{i,j} |\\text{labels}_{ij}|}\n",
    "\\end{equation}\n",
    "\n",
    "When you obtain an accuracy value around **0.78**, it means that approximately 78\\% of the labels in your test set are correctly predicted by your model. In other words, your model is accurate in assigning the correct labels to the documents about 78\\% of the time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let lookup more on F1-score, presicion, and recall of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1087\n",
      "           1       0.96      0.88      0.92       719\n",
      "           2       0.77      0.79      0.78       179\n",
      "           3       0.95      0.84      0.89       149\n",
      "           4       0.93      0.81      0.87       189\n",
      "           5       0.87      0.66      0.75       117\n",
      "           6       0.90      0.47      0.62       131\n",
      "           7       0.83      0.56      0.67        89\n",
      "           8       0.72      0.54      0.61        71\n",
      "           9       0.70      0.29      0.41        56\n",
      "\n",
      "   micro avg       0.94      0.84      0.89      2787\n",
      "   macro avg       0.86      0.68      0.75      2787\n",
      "weighted avg       0.93      0.84      0.88      2787\n",
      " samples avg       0.88      0.87      0.87      2787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\anaconda3\\envs\\NLP1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(labels, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
